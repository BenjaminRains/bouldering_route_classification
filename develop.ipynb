{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c220486d",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c4626a",
   "metadata": {},
   "source": [
    "### Collecting hold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a437206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1b70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img,cvt=True):\n",
    "    if cvt:\n",
    "        if len(img.shape) == 2:\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    \n",
    "# e.g. corners = [(2.0, 1.0), (4.0, 5.0), (7.0, 8.0)]\n",
    "def polygonal_area(corners):\n",
    "    n = len(corners) # of corners\n",
    "    area = 0.0\n",
    "    for i in range(n):\n",
    "        j = (i + 1) % n\n",
    "        area += corners[i][0] * corners[j][1]\n",
    "        area -= corners[j][0] * corners[i][1]\n",
    "    area = abs(area) / 2.0\n",
    "    return area\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path) as f:\n",
    "        json_data = json.load(f)\n",
    "        hold = json_data[\"shapes\"][0]\n",
    "        hold_area = polygonal_area(hold[\"points\"])\n",
    "        \n",
    "def show_image(img,cvt=True):\n",
    "    if cvt:\n",
    "        if len(img.shape) == 2:\n",
    "            cv2.imshow('img',img)\n",
    "        else:\n",
    "            cv2.imshow('img',cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "         cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()       \n",
    "    \n",
    "        \n",
    "def resize_image(image, width=750, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688191bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot_image(img_src)\n",
    "#read_json('slab_images/image (1).json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a36287",
   "metadata": {},
   "source": [
    "### Climbing hold dot detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef20a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio(n1, n2):\n",
    "  \"\"\"Calculates similarity score between 2 numbers\n",
    "  Args:\n",
    "      n1 (int): first number\n",
    "      n2 (int): second number\n",
    "  Returns:\n",
    "      (float): similarity score between the 2 numbers\n",
    "  \"\"\"\n",
    "  return 1 - abs(n1 - n2) / (n1 + n2)\n",
    "\n",
    "def subimage_from_coords(img_src,x1,y1,x2,y2):\n",
    "    return img_src[y1:y2,x1:x2]\n",
    "\n",
    "def percentage_dark(img_src,threshold):\n",
    "    num_dark = np.sum(img_src < threshold)\n",
    "    num_light =  np.sum(img_src >= threshold)\n",
    "    return num_dark/(num_light+num_dark)\n",
    "\n",
    "def find_dots(img_src):\n",
    "    \"\"\"Climbing dot detection using connected component analysis\n",
    "    Args:\n",
    "        img_src (Mat): the image source\n",
    "    Returns:\n",
    "        dot_centres (list): list of (x,y) coordinates of the climbing dots\n",
    "    \"\"\"    \n",
    "    # Create grayscale image\n",
    "    gray_img = cv2.cvtColor(img_src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold search area\n",
    "    binary_img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY_INV, 131, 15)\n",
    "    \n",
    "    # Blob detection\n",
    "    _, _, boxes, _ = cv2.connectedComponentsWithStats(binary_img)\n",
    "    \n",
    "    # First box is the background\n",
    "    boxes = boxes[1:]\n",
    "    \n",
    "    # Threshold blobs by pixel area and percentage of dark pixels\n",
    "    filtered_boxes = []\n",
    "    for x,y,w,h,pixels in boxes:\n",
    "        area_limit = (80 < pixels < 400)\n",
    "        subimage = subimage_from_coords(gray_img,x,y,x+w,y+h)\n",
    "        p = percentage_dark(subimage,80)\n",
    "        p_limit = 0.4 < p < 0.6\n",
    "        if p_limit and area_limit and ratio(w,h) > 0.75:\n",
    "            filtered_boxes.append((x,y,w,h))\n",
    "\n",
    "    # Create list of dot centres\n",
    "    dot_centres = []\n",
    "    for x,y,w,h in filtered_boxes:\n",
    "        cv2.rectangle(img_src, (x,y), (x+w,y+h), (0,255,0),2) # draw rectangle around the detected dots\n",
    "        dot_centre = (round(x+(w/2)),round(y+(h/2)))\n",
    "        dot_centres.append(dot_centre)\n",
    "    \n",
    "    #show_image(resize_image(img_src))\n",
    "        \n",
    "    return dot_centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378142f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cm/pixel: 0.11770987417480978\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "from statistics import mode\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "\n",
    "def modal_distance(dot_centres):\n",
    "    \"\"\"Returns the modal distance between a list of (x,y) coordinates\n",
    "    Args:\n",
    "        dot_centres (list): list of (x,y) coordinates of the climbing dots\n",
    "    Returns:\n",
    "        avg (int): the modal distance\n",
    "    \"\"\"\n",
    "    modal_distance_map = defaultdict(list)\n",
    "    distances = []\n",
    "    for dot_centre in dot_centres:\n",
    "        # Create list of coordinates that excludes the current iterated coordinate\n",
    "        other_centres = dot_centres\n",
    "        other_centres.remove(dot_centre)\n",
    "        # Kd-tree for quick nearest-neighbor lookup\n",
    "        tree = spatial.KDTree(other_centres)\n",
    "        # Append shortest distance to list of distances\n",
    "        dist, idx = tree.query(dot_centre)\n",
    "        rounded_dist = round(dist,-1)\n",
    "        modal_distance_map[rounded_dist].append(dist)\n",
    "    \n",
    "    modal_distance = max(modal_distance_map, key=lambda key: len(modal_distance_map[key]))\n",
    "    dists = modal_distance_map[modal_distance]\n",
    "    return np.mean(dists)\n",
    "    #avg = mode(distances)\n",
    "    #return avg\n",
    "\n",
    "img_src = cv2.imread('slab_images/image (90).jpeg')\n",
    "dot_centres = find_dots(img_src)\n",
    "dist = modal_distance(dot_centres)\n",
    "cv2.line(img_src, (400,400), (400,400+round(dist)), (255,0,0), 5)\n",
    "#show_image(resize_image(img_src))\n",
    "print(f\"cm/pixel: {20/dist}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d2715",
   "metadata": {},
   "source": [
    "### Route detection and sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b08d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import scipy.cluster\n",
    "import pickle\n",
    "\n",
    "def filter_route(file_name):\n",
    "    \n",
    "    # Load hold data from the file\n",
    "    with open(f'tensor_data/{file_name}.pickle', 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    \n",
    "    # Load image file\n",
    "    img = cv2.imread(f'route_images/{file_name}.jpg')\n",
    "    \n",
    "    # Retrieve required colour\n",
    "    expected_colour = file_name.split(\"_\")[0]\n",
    "    print(expected_colour)\n",
    "    \n",
    "    # Retrieve indices of all holds that are relevant to the route by its colour\n",
    "    route_indices = []\n",
    "    for idx, bb in enumerate(data['pred_boxes']):\n",
    "        contours = data['contours'][idx]\n",
    "        r_bb = np.round(bb).astype('int')\n",
    "        \n",
    "        # Cut out hold\n",
    "        mask = np.zeros(img.shape, np.uint8) # Create mask where white is what we want, black otherwise\n",
    "        cv2.drawContours(mask, contours, -1, (255,255,255), -1)\n",
    "        extracted_hold = np.zeros(img.shape, np.uint8) # Extract out the object and place into output image\n",
    "        extracted_hold[mask > 0] = img[mask > 0]\n",
    "        \n",
    "        # Retrieve colour of hold\n",
    "        hold_img = subimage_from_coords(extracted_hold,r_bb[0],r_bb[1],r_bb[2],r_bb[3])\n",
    "        hold_colour = get_hold_colour(hold_img)\n",
    "        \n",
    "        if expected_colour in hold_colour:\n",
    "            route_indices.append(idx)\n",
    "            \n",
    "    return data, route_indices\n",
    "        \n",
    "        \n",
    "\n",
    "def rgb_trueblack(rgb_values):\n",
    "    \"\"\"Check if the given RGB value is very close to the blackest black\n",
    "    Args:\n",
    "        rgb_values (tuple): (r, g, b)\n",
    "    Returns:\n",
    "        boolean: True if the given RGB value is very close to the blackest black\n",
    "    \"\"\"\n",
    "    return (rgb_values[0] < 10 and rgb_values[1] < 10 and rgb_values[2] < 10)\n",
    "\n",
    "def rgb_kmeans(img,num_clusters):\n",
    "    \"\"\"Perform K-Means clustering on an image with a specified number of clusters\n",
    "    Args:\n",
    "        img (Mat): input image\n",
    "        num_clusters (int): number of clusters (K) for K-Means\n",
    "    Returns:\n",
    "        rgb_centres, index_max (tuple): rgb values for centres of clusters, index of the rgb centre with the highest frequency\n",
    "    \"\"\"\n",
    "    # Re-format img\n",
    "    ar = np.asarray(img)\n",
    "    shape = ar.shape\n",
    "    ar = ar.reshape(np.product(shape[:2]), shape[2]).astype(float)\n",
    "    \n",
    "    # Perform K-Means clustering\n",
    "    rgb_centres, _ = scipy.cluster.vq.kmeans(ar, num_clusters)\n",
    "    rgb_centres = [c for c in rgb_centres if not rgb_trueblack(c)]\n",
    "    vecs, _ = scipy.cluster.vq.vq(ar, rgb_centres)\n",
    "    counts, bins = np.histogram(vecs, len(rgb_centres))\n",
    "    \n",
    "    # Index of the RGB array which holds the highest frequency\n",
    "    index_max = np.argmax(counts)\n",
    "    \n",
    "    return (rgb_centres,index_max)\n",
    "\n",
    "def rgb_similar(rgb_array):\n",
    "    \"\"\"Check if the R,G,B values in a given RGB array are similar to each other\n",
    "    Args:\n",
    "        rgb_array (array-like): (r,g,b)\n",
    "    Returns:\n",
    "        boolean: True if the R,G,B values in a given RGB array are similar to each other\n",
    "    \"\"\"\n",
    "    abs_differences = [abs(a-b) for a, b in combinations(rgb_array, 2)]\n",
    "    return (abs_differences[0] < 20 and abs_differences[1] < 20 and abs_differences[2] < 20)\n",
    "\n",
    "def rgb_thres(rgb_array,threshold,direction):\n",
    "    \"\"\"Check if the R,G,B values in a given RGB array are greater/lower than a specified threshold\n",
    "    Args:\n",
    "        rgb_array (array-like): (r,g,b)\n",
    "        threshold (int): threshold value in range (0,256)\n",
    "        direction (int): -1 for lower than threhsold, 1 for higher than threshold\n",
    "    Returns:\n",
    "        boolean: True if the R,G,B values in a given RGB array are greater/lower than a specified threshold\n",
    "        \n",
    "    \"\"\"\n",
    "    if direction == -1:\n",
    "        return (rgb_array[0] < threshold and rgb_array[1] < threshold and rgb_array[2] < threshold)\n",
    "    elif direction == 1:\n",
    "        return (rgb_array[0] > threshold and rgb_array[1] > threshold and rgb_array[2] > threshold)\n",
    "    else:\n",
    "        raise Exception(f\"The direction {direction} is not valid. It must be -1 or 1.\")\n",
    "\n",
    "def check_black_or_white(rgb_centres):\n",
    "    # If the RGB values of the two centres are similar then this mostly comprises of white or black colours\n",
    "    if rgb_similar(rgb_centres[0]) and rgb_similar(rgb_centres[1]):\n",
    "        \n",
    "        # Check for black\n",
    "        if (rgb_thres(rgb_centres[0],80,-1) and rgb_thres(rgb_centres[1],150,-1)):\n",
    "            return -1\n",
    "        elif (rgb_thres(rgb_centres[1],80,-1) and rgb_thres(rgb_centres[0],155,-1)):\n",
    "            return -1\n",
    "        \n",
    "        # If it's not black then it must be white\n",
    "        else:\n",
    "            return 1\n",
    "    # Otherwise this is not black or white, it must be a different colour\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def color_from_hsv(h):\n",
    "    if 0 <= h < 10:\n",
    "        return 'red'\n",
    "    elif 10 <= h < 20:\n",
    "        return 'orange'\n",
    "    elif 20 <= h < 40:\n",
    "        return 'yellow'\n",
    "    elif 40 <= h < 70:\n",
    "        return 'green'\n",
    "    elif 65 <= h < 125:\n",
    "        return 'blue'\n",
    "    elif 125 <= h < 165:\n",
    "        return 'purple'\n",
    "    elif 165 <= h < 176:\n",
    "        return 'pink'\n",
    "    # Some holds at this hue range are hard to distinguish into pink or red so return both\n",
    "    elif 176 <= h < 178.6:\n",
    "        return 'pink/red'\n",
    "    else:\n",
    "        return 'red'\n",
    "        \n",
    "def get_hold_colour(subimg):\n",
    "    \n",
    "    # Convert image to RGB space\n",
    "    img_rgb = cv2.cvtColor(subimg, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform K-Means clustering to split image into 3 main colours\n",
    "    rgb_centres, idx_max = rgb_kmeans(img_rgb,num_clusters=3)\n",
    "    \n",
    "    # Retrieve the strongest RGB colour\n",
    "    main_rgb = rgb_centres[idx_max]\n",
    "    \n",
    "    # If the main RGB colour is black or white then return it\n",
    "    if rgb_thres(main_rgb,40,-1):\n",
    "        return 'black'\n",
    "    if rgb_thres(main_rgb,155,1):\n",
    "        return 'white'\n",
    "    \n",
    "    # Otherwise perform a stronger check for whether it's black or white\n",
    "    # Necessary as black holds can be covered in white chalk\n",
    "    # or white holds can be turned blacker from wear over time\n",
    "    bw_check = check_black_or_white(rgb_centres)\n",
    "    if bw_check == 1:\n",
    "        return 'white'\n",
    "    elif bw_check == -1:\n",
    "        return 'black'\n",
    "    \n",
    "    # If the hold is not black or white then it must be a colour so find the colour\n",
    "    else:\n",
    "        # Normalise the rgb values\n",
    "        (r, g, b) = (main_rgb[0] / 255, main_rgb[1] / 255, main_rgb[2] / 255)\n",
    "        # Convert to HSV\n",
    "        (h, _, _) = colorsys.rgb_to_hsv(r, g, b)\n",
    "        # Return the colour from the HSV value\n",
    "        return color_from_hsv(h*179)\n",
    "\n",
    "file_name = \"green_VB (19)\"\n",
    "img = cv2.imread(f'route_images/{file_name}.jpg')\n",
    "data, route_indices = filter_route(file_name)\n",
    "print(len(route_indices))\n",
    "for i in route_indices:\n",
    "    r_bb = np.round(data['pred_boxes'][i]).astype('int')\n",
    "    cv2.rectangle(img, (r_bb[0],r_bb[1]), (r_bb[2],r_bb[3]), (255,0,0),4) # draw rectangle around the detected dots\n",
    "show_image(resize_image(img,width=300),cvt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b262017",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509d349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
